{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.test.org/chem_ontologies/chem_ontology.owl#\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"D:\\CursorProj\\Chem-Ontology-Constructor\")\n",
    "os.environ[\"PROJECT_ROOT\"] = \"D:\\\\CursorProj\\\\Chem-Ontology-Constructor\\\\\"\n",
    "\n",
    "from owlready2 import *\n",
    "from autonogy_constructor.idea.workflow import create_main_graph, MainState\n",
    "from config.settings import ONTOLOGY_CONFIG\n",
    "\n",
    "# 加载本体\n",
    "onto = ONTOLOGY_CONFIG[\"ontology\"]\n",
    "onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CursorProj\\Chem-Ontology-Constructor\\autonogy_constructor\\idea\\dreamer_team\\base_finder.py:34: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  self.llm = ChatOpenAI(temperature=0.7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At 'reflect' node, 'condition' branch found unknown target 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 创建主工作流\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m main_graph \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_main_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43monto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 初始化状态\u001b[39;00m\n\u001b[0;32m      5\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m MainState(\n\u001b[0;32m      6\u001b[0m     stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquerying\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     query_state\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mD:\\CursorProj\\Chem-Ontology-Constructor\\autonogy_constructor\\idea\\workflow.py:34\u001b[0m, in \u001b[0;36mcreate_main_graph\u001b[1;34m(ontology)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Create subgraphs\u001b[39;00m\n\u001b[0;32m     33\u001b[0m query_graph \u001b[38;5;241m=\u001b[39m create_query_graph(ontology)\n\u001b[1;32m---> 34\u001b[0m dreamer_graph \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dreamer_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m critic_graph \u001b[38;5;241m=\u001b[39m create_critic_graph()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Add subgraphs as nodes\u001b[39;00m\n",
      "File \u001b[1;32mD:\\CursorProj\\Chem-Ontology-Constructor\\autonogy_constructor\\idea\\dreamer_team\\dreamer_workflow.py:40\u001b[0m, in \u001b[0;36mcreate_dreamer_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m workflow \u001b[38;5;241m=\u001b[39m StateGraph(DreamerState)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Create finder subgraphs\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m evidence_graph \u001b[38;5;241m=\u001b[39m \u001b[43mEvidenceFinder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_finder_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m knowledge_graph \u001b[38;5;241m=\u001b[39m KnowledgeFinder()\u001b[38;5;241m.\u001b[39mcreate_finder_graph()\n\u001b[0;32m     42\u001b[0m methodology_graph \u001b[38;5;241m=\u001b[39m MethodologyFinder()\u001b[38;5;241m.\u001b[39mcreate_finder_graph()\n",
      "File \u001b[1;32mD:\\CursorProj\\Chem-Ontology-Constructor\\autonogy_constructor\\idea\\dreamer_team\\base_finder.py:116\u001b[0m, in \u001b[0;36mBaseFinder.create_finder_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Set entry and exit\u001b[39;00m\n\u001b[0;32m    114\u001b[0m workflow\u001b[38;5;241m.\u001b[39mset_entry_point(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalyze\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\AnacondaEnPs\\envs\\OntologyConstruction\\Lib\\site-packages\\langgraph\\graph\\state.py:448\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[1;34m(self, checkpointer, store, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    445\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[0;32m    457\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    465\u001b[0m     ]\n\u001b[0;32m    466\u001b[0m )\n",
      "File \u001b[1;32md:\\AnacondaEnPs\\envs\\OntologyConstruction\\Lib\\site-packages\\langgraph\\graph\\graph.py:386\u001b[0m, in \u001b[0;36mGraph.validate\u001b[1;34m(self, interrupt)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m end \u001b[38;5;129;01min\u001b[39;00m branch\u001b[38;5;241m.\u001b[39mends\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m END:\n\u001b[1;32m--> 386\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    387\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m node, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m branch found unknown target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    388\u001b[0m             )\n\u001b[0;32m    389\u001b[0m         all_targets\u001b[38;5;241m.\u001b[39madd(end)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: At 'reflect' node, 'condition' branch found unknown target 'query'"
     ]
    }
   ],
   "source": [
    "# 创建主工作流\n",
    "main_graph = create_main_graph(onto)\n",
    "\n",
    "# 初始化状态\n",
    "initial_state = MainState(\n",
    "    stage=\"querying\",\n",
    "    query_state={},\n",
    "    dreamer_state={},\n",
    "    critic_state={},\n",
    "    ontology=onto,\n",
    "    current_class=\"calixarene\",  # 单领域分析示例\n",
    "    target_class=None,  # 不进行跨领域分析\n",
    "    research_ideas=[],\n",
    "    evaluations=[],\n",
    "    messages=[],\n",
    "    done=False\n",
    ")\n",
    "\n",
    "# 运行工作流\n",
    "for output in main_graph.stream(initial_state):\n",
    "    # 打印每个阶段的状态\n",
    "    print(f\"\\nStage: {output['stage']}\")\n",
    "    \n",
    "    if output.get(\"research_ideas\"):\n",
    "        print(\"\\nGenerated Ideas:\")\n",
    "        for idea in output[\"research_ideas\"]:\n",
    "            print(f\"\\nIdea based on {idea['gap_type']}:\")\n",
    "            print(f\"Research Question: {idea['research_question']}\")\n",
    "            print(f\"Methodology: {idea['methodology']}\")\n",
    "    \n",
    "    if output.get(\"evaluations\"):\n",
    "        print(\"\\nEvaluations:\")\n",
    "        for eval in output[\"evaluations\"]:\n",
    "            print(f\"\\nScores: {eval['scores']}\")\n",
    "            print(f\"Suggestions: {eval['suggestions']}\")\n",
    "    \n",
    "    if output.get(\"messages\"):\n",
    "        print(\"\\nSystem Messages:\")\n",
    "        for msg in output[\"messages\"]:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化跨领域分析状态\n",
    "cross_domain_state = MainState(\n",
    "    stage=\"querying\",\n",
    "    query_state={},\n",
    "    dreamer_state={},\n",
    "    critic_state={},\n",
    "    ontology=onto,\n",
    "    current_class=\"calixarene\",\n",
    "    target_class=\"crown_ether\",  # 指定目标类进行跨领域分析\n",
    "    research_ideas=[],\n",
    "    evaluations=[],\n",
    "    messages=[],\n",
    "    done=False\n",
    ")\n",
    "\n",
    "# 运行工作流\n",
    "for output in main_graph.stream(cross_domain_state):\n",
    "    print(f\"\\nStage: {output['stage']}\")\n",
    "    \n",
    "    if output.get(\"research_ideas\"):\n",
    "        print(\"\\nGenerated Cross-domain Ideas:\")\n",
    "        for idea in output[\"research_ideas\"]:\n",
    "            print(f\"\\nIdea based on {idea['gap_type']}:\")\n",
    "            print(f\"Research Question: {idea['research_question']}\")\n",
    "            print(f\"Methodology: {idea['methodology']}\")\n",
    "    \n",
    "    if output.get(\"evaluations\"):\n",
    "        print(\"\\nEvaluations:\")\n",
    "        for eval in output[\"evaluations\"]:\n",
    "            print(f\"\\nScores: {eval['scores']}\")\n",
    "            print(f\"Suggestions: {eval['suggestions']}\")\n",
    "    \n",
    "    if output.get(\"messages\"):\n",
    "        print(\"\\nSystem Messages:\")\n",
    "        for msg in output[\"messages\"]:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ideas(state: MainState):\n",
    "    \"\"\"汇总生成的研究想法\"\"\"\n",
    "    print(\"\\n=== Research Ideas Summary ===\")\n",
    "    \n",
    "    # 按gap类型分组\n",
    "    ideas_by_gap = {}\n",
    "    for idea in state[\"research_ideas\"]:\n",
    "        gap_type = idea[\"gap_type\"]\n",
    "        if gap_type not in ideas_by_gap:\n",
    "            ideas_by_gap[gap_type] = []\n",
    "        ideas_by_gap[gap_type].append(idea)\n",
    "    \n",
    "    # 打印汇总\n",
    "    for gap_type, ideas in ideas_by_gap.items():\n",
    "        print(f\"\\n{gap_type.upper()} based ideas:\")\n",
    "        for i, idea in enumerate(ideas, 1):\n",
    "            print(f\"\\n{i}. Research Question: {idea['research_question']}\")\n",
    "            # 找到对应的评估\n",
    "            for eval in state[\"evaluations\"]:\n",
    "                if eval[\"idea\"] == idea:\n",
    "                    print(f\"   Scores: {eval['scores']}\")\n",
    "                    break\n",
    "\n",
    "# 汇总单领域分析结果\n",
    "summarize_ideas(initial_state)\n",
    "\n",
    "# 汇总跨领域分析结果\n",
    "summarize_ideas(cross_domain_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OntologyConstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
